[{"id":0,"href":"/mobile_robotics/sensors/","title":"Sensors","section":"Welcome to mobile robotics","content":"Sensors #  Depending on your robots, you should have a set of 3 or 4 different sensors contemporarily receiving data about your robots location and it\u0026rsquo;s environment. The possible sensors you may have are: magnetometer, encoders, external positioning, lidar. There might be also an option to include an accelerometer too.\nSome sensors will have a much higher reliability than others. For example, the external positioning is likely to be far more accurate than the encoders, as it is always observing the robot from a fixed, external reference frame.\nThe encoders, even if the easiest to code, as there is a continuous and simple feedback about the motor distance; can be thought to be not as reliable as they have to work on the no-slip assumption. On the current code, an assumption about their turn radius has also been made. Causing a slight variance if the robot actually has a turn radius which differs from the one assumed.\nFor more information about how the main body of code incorporates the code, proceed to the programming section\nSensor Code Structure #  The code was made in order to attempt to make the combination of information between the sensors as easily as possible\nTo do this, a structure, seen below was created.\n The BaseLoggable class, creates separate message format that both sensors and motors (actuators) will inherit, (and records everything that is sensed or occurred). The sensors class will then configure the sensor by using the YAML file.\nWorking through the tree, the BaseLogger class logs any data it receives, and initially sets the message format for both the BaseSensor and Motors. The BaseSensor the configuration of the sensor, (given in the yaml file), and will configure the correct message type, driver etc.. to the current sensor being recorded. Finally the Sensor records the data, given the message structure and driver.\nSensors #  Lidar #  The lidar works by via laser triangulation. It releases very fast pulses of light toward a target and measures the amount of time it takes for the light to travel back. The message will be saved in the form of:\ndef log_scan(self, msg: LaserScanMessage): \u0026quot;\u0026quot;\u0026quot;Log the sensor data to disk.\u0026quot;\u0026quot;\u0026quot; self.logger.log( msg.stamp_s, msg.angle_min_rad, msg.angle_max_rad, msg.time_increment_s, msg.range_min_m, msg.range_max_m, str(msg.ranges), str(msg.intensities), str(msg.angles), ) Here is an example scan that the lidar made of it\u0026rsquo;s surrounding space in an office.\n Of course the information is still contains a fair amount of noise, as students, you will have to filter the information to then be able to use it in order to understand where the robot is with respect to neighbouring walls and maybe other rovers.\nExternal Localisation #  The external localisation is a way to simulate gps or other external positioning methods by using camera vision. The camera recognises the tags, and to due to the nature and distinctiveness of the tags, it is able to very effectively understand both the position and rotation of the tags.\n def read(self) -\u0026gt; RobotStateMessage: # TODO convert self.data to RobotStateMessage msg = RobotStateMessage() if self.data is None: return msg msg.stamp_s = self.data[0] msg.x_m = self.data[2] msg.y_m = self.data[3] msg.z_m = self.data[4] msg.roll_rad = self.data[5] msg.pitch_rad = self.data[6] msg.yaw_rad = self.data[7] return msg Rotary Encoders #  The encoders are electromechanical devices that detects the angular position or motion of a shaft. The Pi-top was configured in such a way that the encoders return angle travelled. As a result the velocity calculated won\u0026rsquo;t be as accurate as other sensors.\nCompass/magnetometer #  The magnetometer is a device that measures magnetic field. This sensor will return the yaw of the vessel or vehicle.\n"},{"id":1,"href":"/mobile_robotics/programming/","title":"Programming","section":"Welcome to mobile robotics","content":"Programming #  Setting Up #  Now that you have tested that the robot functions correctly. We will begin to go through the main body of code that you will be using throughout your project. It is highly suggested to install VS code, (a code editor like spyder and Jupyter Notebook), as it will show all the python files that you need to work with on the side.\nBoth the Land Rover and the Robotic vessel will use the same code. Depending on your robot, you will need to configure it in the \u0026ldquo;configuration.yaml\u0026rdquo; file.\nThe installation will take you to a github repository. To install, click on the code button then install the code by clicking the \u0026lsquo;download zip\u0026rsquo; in the dropdown menu\n Install VSCode  Main Code   Once installed, extract the folder and open mobile_robotics_python in vs code within mobile_robotics_python-main/mobile_robotics_python-main/src open the folder mobile_robotics_python. Once opened the folder should look something like this: Folder Introduction #  This folder will be where you will write your code throughout the project. Although the code might look a little intimidating at first. Most of the files within the folder will work in the background and therefore will not need to be tampered with.\nThe objective of your course will be to create new localization_solutions and navigations_solutions so that the robot is able to navigate autonomously to its best ability. Here below you can see what the current code should do with basic localisation and navigation code.\n  Simplified model of structure #  When the the code is run, it will got through the main loop within robot.py. In simple words it goes in a \u0026lsquo;sense, think, act\u0026rsquo; loop.\n as you can see in the python page, within the loop:\nwhile not self.mission_control.finished: there is the 3 steps: First the code records all its sensors (it will vary depending on your robot):\nSensing #   measurements = [] if self.compass is not None: msg = self.compass.read() measurements.append(msg) if self.encoder is not None: self.encoder.yaw_rad = self.compass.yaw_rad msg = self.encoder.read() measurements.append(msg) you may now change these variables based upon what robot you have:\nIf you have the Pitop, it might be useful to record the compass, encoder, lidar and external_positioning\nIf you have the robotic vessel, it might be useful to record the encoder, accelerometer, magnetometer and external_positioning\nThinking #  Once the robot has updated all the sensor data, it will use the information in order to understand it\u0026rsquo;s current location. At the moment the code is using a simple \u0026lsquo;dead_reckoning\u0026rsquo; algorithm. You may find the file inside the location_solutions folder\n if len(measurements) \u0026gt; 0: for measurement in sorted(measurements, key=lambda m: m.stamp_s): self.state = self.localisation.update(measurement) Create a new file in the same location_solution folder, name it (***.py), then once you have finished the code within, you will have to change configurations to use that file instead of dead reckoning as so:\nEditing localisation.py #  Add another if statement in the localisation.py file in the mobile_robotics, (main) folder. This file directs the robot function to the appropriate localisation_solution by reading the configuration.yaml file.\n Remember, if you want to follow the same structure, you will need to have a predict and update function within your new localization solution. For example, you may choose to implement the location predictions within the main robot loop, (as it isn\u0026rsquo;t currently being utilized).  Editing configuration.yaml #  Change the driver of localization within the configuration.yaml file, (found in the configuration folder). All files refer to this yaml in order to understand which file is to be implemented. In future you may want to change some of the offsets within the file as its likely that there is an offset between your sensors, motors and the centre of the robot. You will also be able to change the configuration of your robot. Aka changing your configuration to the correct encoder drivers and compass/magnetometer depending on if you are using the robotic vessel or pitop.  Now that you have learned a little more about the configuration yaml and the main robot function. Try creating a new waypoint mission yourself and changing the configuration.yaml !  Acting #  The current navigation solution, naive_robot_move.py has a very basic and naive navigation algorithm. You will have to develop your own which is a little smarter, in which it can react upon its current situation, (both long and short term). An example of this, is if there is an obstacle between the robot and it\u0026rsquo;s current waypoint.\nThe current solution simply computes the difference between its current position and the waypoint and will move the motors accordingly. As you may observe in this video, if the robot accidentally misses it\u0026rsquo;s waypoint threshold, it will simply carry on.\nSimilarly to what you did for the thinking section, you will need to create a new python file inside the folder called navigations_solutions. You will then need to edit both your configuration.yaml file and within navigation.py in order to follow your new navigation solution \u0026ldquo;***.py\u0026rdquo;, instead of the naive_robot_move.py\n"},{"id":2,"href":"/mobile_robotics/intelligent_mobile_robotics/","title":"Intelligent mobile robotics","section":"Welcome to mobile robotics","content":"Intelligent mobile robotics #  You will be using a Pi-top for your mobile_robotics course. We should have pre-assembled your kit in advance, if this has not been done in your case, or if there are some missing parts please contact a member of staff. Your kit should look something like this:\n Where you will have\n 1 x Pitop 1 x Rasberry-pi (should be within Pitop) 1 x microSD card 1 x assembled robot 1 x Lidar  If you need to place the Rasberry-pi inside your Pi-top, please follow this Assembly tutorial.\nYou should now be ready to go !\nIf your rasberry-pi hasn\u0026rsquo;t been configured, please follow the Pi Configuration section. If it has progress to the programming section to learn more about the code you will work upon.\nYou can then test your robot, to see if the motors respond, using the remote, or simply using the initial square movement code provided in the programming section,\n"},{"id":3,"href":"/mobile_robotics/maritime_robotics/","title":"Maritime robotics","section":"Welcome to mobile robotics","content":"Maritime Robotics #  In your kit you will have a semi-constructed robotic-vessel that will look something like this:\nHopefully a pre-configured raspberry pi will be assigned to you. If not or if the memory got erased, please follow the steps in pi_configuration\nIf the pi is configured, and the robot is running the square code, (download the main code and running it).\nProgramming page  "},{"id":4,"href":"/mobile_robotics/maritime_robotics/platform/","title":"Platform","section":"Maritime robotics","content":"Platform #  Fabrication #  Marine platforms are fabricated from common PVC tubing and fittings. Please note that “Push-Fit” and “Solvent Weld” types have different outer diameters and are not compatible. As these platforms are glued together, all components must be “Solvent Weld” compatible.\n  Materials Required ↕  • x1 - 3m 40mm Solvent Weld PVC Pipe : Example\n Please cut the pipe into:\n x4 – 5.5cm Tubes x2 – 40cm Tubes x2 – 16.5cm Tubes x2 – 17.5cm Tubes x1 – 25cm Tube   • x8 – 40mm 90° Bends : Example\n• x2 – 40mm Universal Equal Tee (These are compatible with both Push-Fit and Solvent Weld piping) : Example\n• x6 – 40mm Pipe Clips Solvent Weld (Make sure they are Solvent Weld type as their constructions is from ABS instead of Polypropylene, allowing them to be glued to the PVC pipes) : Example\n• x1 – Solvent Cement (Please make sure it can weld both ABS and PVC, like the example below. Use in a well-ventilated area and wear a mask if possible, fumes are very strong) : Example\n   Process #  It is recommended to go through the steps without gluing anything first to familiarise yourself). To form one float:  Following the cement instructions, form two “C”s made up of two 90° bends and a 5.5cm tube each. The glue dries fairly quickly, make sure the bends are aligned using the fabrication lines on the plastic. Grab one of the “C”s and weld one 40cm tube. You should now have something that resembles an “L” shape. Connect the one 16.5cm tube and one 17.5cm tube to the equal tee according to the following diagram (pay attention to the curve in the Tee being closer to the longer piece of tubing).  Glue the end of the 17.5cm tube to the empty 90° bend in the “L” assembly from step 2. At this point, your assembly should have a “U” shape. Using the second “C” from step above, close the assembly by gluing the 40cm tube and 16.5cm to the empty 90° bends. Leave to dry and repeat steps 1-5 to form the second float.  Centre Piece assembly #     Grab the 25cm tube and mark 5cm from one end.\n  Place 3 pipe clips at one end, aligning the one closest to the end with the mark above. Make sure the pipe clips are aligned with each other and draw a line across the top of them and the tube (this will make alignment easier after the glue is applied).\n  Rotate the middle clip by 180 degrees and mark the tube on the opposite side.\n  One by one, apply glue to the tube and the inside of each pipe clip and weld them together. Leave to dry for 10min.\n  Repeat steps 1-4 for the other end, making sure that the clips are aligned with the previous ones as well.\n  Assembly #  This section describes how to put together one marine platform. Before starting, make sure you have gathered all the following materials: PVC Parts\n• x2 Floats\n• x1 Centre Tube with Pipe Clips\n3D Printed Assembly #    3D Printed Assembly components ↕  • x2 Lower Bracket (3D Printed)\n• x2 Motor Pillars (Left/Right 3D Printed)\n• x2 Motor Cones (3D Printed)\n• x2 Motor Domes (3D Printed)\n• x2 Velcro Attachments (3D Printed)\n• x10 M4 – 20mm Bolts\n• x10 M4 – 30mm Bolts\n• x20 M4 Nylock Nuts\n• x40 M4 Washers\n• x2 2mm x 300mm Threaded Shaft (Trim to right length from threaded end)\n• x1 RH 30mm Propeller\n• x1 LH 30mm Propeller\n• x2 2mm x 2mm Shaft Couplers\n• x2 BL-1510 Brushless Motors\n• x2 2mm Bearings\nControl Box • x1 Battery\n• x1 Raspberry Pi with Sense Hat\n• X1 Raspberry Pi Case with Foam Block\n• x1 Connection Block\n• x1 DC/DC Converter\n• x1 Pololu Micro Maestro Controller\n• x2 ESC Motor Controllers\n• x1 Micro USB Cable to USB A\n• x1 Micro USB Cable to Red/Black\n• x1 Double Pin to Cable ends connector\n• Velcro Tape\n   Let’s start by assembling the structure of the marine platform.\n  Grab the two floats and remove the screw caps from each tee and their washers.\n  At either end of the centre piece, insert the screw caps, the plastic washer and finally the black rubber washer (in that order). Make sure the inclined edge of the rubber washer faces towards the end of the tubing.\n  Connect the floats to the centre piece by screwing the caps to the tees. Ensure it is fully tightened as this will prevent water from entering and the rotation of the floats.\n  The structure is now ready! Continue by assembling the motors:\n  Start by attaching one lower bracket (3D Printed) to the pipe clips of the centre piece as illustrated below. Remember to put a washer at either side of the part!\n   Grab the motor pillar (3D Printed) and position the motor in the cross socket. Proceed to attach one end of the coupler.    Take the propeller shaft provided and trim it to 94mm from the threaded end.\n  Press fit a bearing at the end of the motor cone (3D Printed), you can heat it slightly to locally melt the plastic if necessary.\n  Connect the end of the shaft to the coupler\n    Fit the shaft through the bearing and screw the propeller in (Make sure it is the correct propeller for the motor side you are assembling, they will spin in opposite directions). If you find the propeller coming loose during tests, consider super gluing it in place after you are sure they spin in the right direction.\n  You can now attach the motor cone, motor pillar and motor dome together. Insert three M4 – 30mm bolts with their respective washers through the dome first as shown below:\n   Now attach the motor assembly above to the lower bracket, do not forget the washer at either end of the M4 – 30mm bolts.   You have now finished mounting one motor, please repeat steps 1-8 to mount the second one. Let’s now prepare the control box, for reference of where to place the components, please have a look at the following image:    Carry out the connections according to the diagram below:   "},{"id":5,"href":"/mobile_robotics/external_localisation/","title":"External localisation","section":"Welcome to mobile robotics","content":"External localisation #  Expand this text or click the yaml file to find all the assigned aruco tags   Aruco marker setup ↕  For an updated version of what each marker does please check the following yaml file, (as it is the one the pi will read), (website might be out of date).\n   Aruco Tag functionality Aruco Tag functionality Aruco Tag functionality     #0 robot 0 #10 None #20 5s Broadcast   #1 robot 1 #11 None #21 10s Broadcast   #2 robot 2 #12 OK #22 no Broadcast   #3 robot 3 #13 Shutdown #23 None   #4 robot 4 #14 Frame ENU #24 None   #5 robot 5 #15 Frame NED #25 None   #6 robot 6 #16 Broadcast at logging speed #26 None   #7 robot 7 #17 Calibration #27 None   #8 robot 8 #18 1s Broadcast #28 None   #9 robot 9 #19 2s Broadcast #29 None       yaml file  ArUco setup Checklist #  Before Turning on the Pi #  Ensure Camera is in centre of tank and is facing the tank, (and is connected to the pi)\nEnsure No ArUco Markers Are visible in the Camera frame (flip them upside down to ensure they can’t be seen)\nEnsure that the Router is turned on and that it’s Wifi led is on, (doesn’t need to be connected to the internet)\nTurn On the Raspberry pi, (may take a while, if no monitor attached wait 1 minute to ensure everything has booted up before configuring)\nWhen booting the Pi, the ArUco code should start automatically, therefore it is not necessary to connect a keyboard or mouse to the Pi. If desired, a monitor may be connected to transmit all the Pi’s Information, (recommended).\nWhen Pi is turned on #  To newly calibrate the origin location, place the Calibration tag (#27) where desired, (ensure it is flat and not moving), the origin will be located in the centre of this marker. Then Show the ‘OK’ (#22) tag in frame. Only when the 2 tags are recognised in frame will the code save the position.\nIf you want to use the old Calibrated Origin, then the previous step can be skipped by only showing the ‘OK’ (#22) in frame.\nIf the step was done incorrectly, proceed to show the Shut-down tag (#13) together with the ‘OK’ (#22) tag in frame. WAIT 1 minute (to ensure that pi properly switches off), then proceed to turn the pi’s power off then on. (This should reboot the program)\nThe Setup-phase is now completed\nBroadcast Frequency, #  (frequency at which the Server Pi will send the coordinates to the Client Pi’s) has a possible configuration of ‘logging speed’ (~10th of a second), 1s, 2s, 5s, 10s and never. On boot the pi will be initially setup to send the information every 1s.\nTo change the show the desired Broadcast Frequency tag (shown in table below) in frame, with the ‘OK’ tag (#49).\n   Aruco Tag Broadcast speed     #16 at logging speed   #18 every 1s   #19 every 2s   #20 every 5s   #21 every 10s   #22 no broadcast    If a Display is connected to the Pi, the broadcast frequency will be visible as a frame will blink around the screen at every broadcasted interval, (when an ArUco marker is being shown).\nThe Server Pi should Now be all set!\nTo Turn Off the Pi show the Shut-down tag (#13) together with the ‘OK’ (#22) tag in frame. WAIT 1 minute (to ensure that pi properly switches off).\nThe Pi will Log all the ArUco tag information in a csv file of which’ name will be ‘***.csv’ where # is the ArUco Tag’s ID. All these files will be stored in a folder named after the exact time the Pi was booted up, example: ‘2022_07_25_12_34_18’, where is in this order: (‘Year_Month_Day_Hour_Minute_Second’).\nAll information will be saved on the ssd card connected separately. This can be disconnected when the Pi is of to read the information from another computer. (there will be a long usb extension so that it is easily accessible).\nSetting up the Client Pi’s, (Robots) #  Make sure all packages have been installed and the Chrony configuration have been made.\nOpen the Python file\nRun the file\nDebugging #   Expand ↕  If robot is not receiving information\nUncomment the print(broadcast_data) line\nPlace an Aruco Tag infront of the camera, if something is being printed in the console, this means that the aruco tags are being recognised. Therefore you can proceed to the next step (Remember position data will only be broadcasted from the Server Robot once the setup phase is complete) :\nEnsure The Client (Robot) Pi is connected to local Router, as this is the network on which the pi will broadcast the data, if your trying this at home, make sure that the both the host and your pi are connected to the same local network, (it will not work through public wifi\u0026rsquo;s such as the Universities Eduroam)\nEnsure the Port to the one shown on screen from the Raspberry pi, (if so change variable called port to one shown on Server Pi )\nEnsure no Other code has been altered other than what has been instructed.\nIf nothing is still being received please ask help from a member of staff.\n   "},{"id":6,"href":"/mobile_robotics/pi_configuration/","title":"pi_configuration","section":"Welcome to mobile robotics","content":"Raspberry Pi Configuration #  In theory your raspberry pi\u0026rsquo;s should be already configured, if so please do not go through this page. If your pi unfortunately got it\u0026rsquo;s memory erased, or you were handed one with nothing on it, then read ahead.\nInstalling the Main Code #  You can install the main code by writing:\nTo install your main code you will first need to install the git installer, to do this write the following in your pi\u0026rsquo;s terminal, (following code is for linux):\nsudo apt-get install git\nonce it has finished install, type the following command in the terminal, this will install the repository to your pi:\ngit clone https://github.com/ocean-perception/mobile_robotics_python\nif this does not work, please ask for a member of staff for help.\nChrony Configuration #  Chrony is an implementation of NTP, it allows for the pi\u0026rsquo;s to synchronize their time even if internet is not connected to one of them. It acts as a daemon in the background. So when setup it should never need to be reconfigured or edited with afterwards.\nServer Configuration (Camera system Pi) #   Install an editor of your choice (nano, vim, gedit), for example for vim you would write  sudo apt install vim Install chrony with  sudo apt install chrony TBD  Client Configuration (student Raspberry Pi) #   Install an editor of your choice (nano, vim, gedit), for example for vim you would write  sudo apt install vim Install chrony with  sudo apt install chrony Find or ask the IP address of the chrony server in the local network (the wifi router network). It should be something like 192.168.0.X, where the last X will change for a number 0-254. Edit chrony configuration, and add the following line at the top of the file  server 192.168.0.X where X has to be changed for the correct IP. The file is located at /etc/chrony/chrony.conf. To edit it, you will need to use sudo, for example:\nsudo vi /etc/chrony/chrony.conf Verify that you can get the updates. First restart chrony with  sudo systemctl restart chrony and now verify that chrony is using your IP by running the command\nchronyc sources "}]